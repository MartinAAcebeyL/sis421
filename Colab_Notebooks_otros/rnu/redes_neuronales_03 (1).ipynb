{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "redes_neuronales_03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2HWIl36XlPi"
      },
      "source": [
        "# Redes Neuronales con Pytorch\n",
        "\n",
        "## Introduction\n",
        "\n",
        "En este ejercicio se implementa una red neuronal para reconocimiento de digitos utilizando pytorch.\n",
        "\n",
        "Antes de empezar la ejecución de las partes de codigo correspondienters a los ejercicios, se requiere importar todas las librerias necesarias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrkbuyYDXlPk"
      },
      "source": [
        "# utilizado para la manipulación de directorios y rutas\n",
        "import os\n",
        "# Cálculo científico y vectorial para python\n",
        "import numpy as np\n",
        "# Libreria para graficos\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision # torch package for vision related things\n",
        "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
        "import torchvision.datasets as datasets  # Standard datasets\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
        "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
        "from torch import nn  # All neural network modules\n",
        "from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\n",
        "from tqdm import tqdm  # For nice progress bar!\n",
        "\n",
        "# le dice a matplotlib que incruste gráficos en el cuaderno\n",
        "%matplotlib inline"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA63y9BgDGi-"
      },
      "source": [
        "# Here we create our simple neural network. For more details here we are subclassing and\n",
        "# inheriting from nn.Module, this is the most general way to create your networks and\n",
        "# allows for more flexibility. I encourage you to also check out nn.Sequential which\n",
        "# would be easier to use in this scenario but I wanted to show you something that\n",
        "# \"always\" works.\n",
        "class NN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(NN, self).__init__()\n",
        "        # Our first linear layer take input_size, in this case 784 nodes to 50\n",
        "        # and our second linear layer takes 50 to the num_classes we have, in\n",
        "        # this case 10.\n",
        "        self.fc1 = nn.Linear(input_size, 50)\n",
        "        self.fc2 = nn.Linear(50, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x here is the mnist images and we run it through fc1, fc2 that we created above.\n",
        "        we also add a ReLU activation function in between and for that (since it has no parameters)\n",
        "        I recommend using nn.functional (F)\n",
        "        \"\"\"\n",
        "        x = self.fc1(x)\n",
        "        x = F.sigmoid(x)\n",
        "        # x = F.sigmoid(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COAUlsr8DLfF",
        "outputId": "ee80f42a-437f-4756-f052-2add40e0d8be"
      },
      "source": [
        "# Set device cuda for GPU if it's available otherwise run on the CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# Hyperparameters of our neural network which depends on the dataset, and\n",
        "# also just experimenting to see what works well (learning rate for example).\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 2000\n",
        "num_epochs = 3"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10BjWiz3DYmW",
        "outputId": "bbe85636-a64b-4663-d1f0-e59589c26202"
      },
      "source": [
        "# Load Training and Test data\n",
        "train_dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.MNIST(root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True)\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MtcDzEqEqeO"
      },
      "source": [
        "# Initialize network\n",
        "model = NN(input_size=input_size, num_classes=num_classes).to(device)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOXxAOpEFiCT"
      },
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNVVsm2uXlPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7c15a42-adf4-4404-d9ea-0dad802a8267"
      },
      "source": [
        "# Train Network\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
        "    # for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "    \n",
        "        # Get data to cuda if possible\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # print(data.shape)\n",
        "        # Get to correct shape\n",
        "        data = data.reshape(data.shape[0], -1)\n",
        "        # print(data.shape)\n",
        "        # print(\"-\"*30)\n",
        "        # forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "\n",
            "  3%|▎         | 1/30 [00:00<00:04,  6.41it/s]\u001b[A\n",
            "  7%|▋         | 2/30 [00:00<00:04,  6.53it/s]\u001b[A\n",
            " 10%|█         | 3/30 [00:00<00:04,  6.63it/s]\u001b[A\n",
            " 13%|█▎        | 4/30 [00:00<00:03,  6.57it/s]\u001b[A\n",
            " 17%|█▋        | 5/30 [00:00<00:03,  6.63it/s]\u001b[A\n",
            " 20%|██        | 6/30 [00:00<00:03,  6.74it/s]\u001b[A\n",
            " 23%|██▎       | 7/30 [00:01<00:03,  6.74it/s]\u001b[A\n",
            " 27%|██▋       | 8/30 [00:01<00:03,  6.76it/s]\u001b[A\n",
            " 30%|███       | 9/30 [00:01<00:03,  6.81it/s]\u001b[A\n",
            " 33%|███▎      | 10/30 [00:01<00:02,  6.91it/s]\u001b[A\n",
            " 37%|███▋      | 11/30 [00:01<00:02,  6.93it/s]\u001b[A\n",
            " 40%|████      | 12/30 [00:01<00:02,  6.73it/s]\u001b[A\n",
            " 43%|████▎     | 13/30 [00:01<00:02,  6.60it/s]\u001b[A\n",
            " 47%|████▋     | 14/30 [00:02<00:02,  6.53it/s]\u001b[A\n",
            " 50%|█████     | 15/30 [00:02<00:02,  6.67it/s]\u001b[A\n",
            " 53%|█████▎    | 16/30 [00:02<00:02,  6.77it/s]\u001b[A\n",
            " 57%|█████▋    | 17/30 [00:02<00:01,  6.86it/s]\u001b[A\n",
            " 60%|██████    | 18/30 [00:02<00:01,  6.85it/s]\u001b[A\n",
            " 63%|██████▎   | 19/30 [00:02<00:01,  6.85it/s]\u001b[A\n",
            " 67%|██████▋   | 20/30 [00:02<00:01,  6.92it/s]\u001b[A\n",
            " 70%|███████   | 21/30 [00:03<00:01,  6.99it/s]\u001b[A\n",
            " 73%|███████▎  | 22/30 [00:03<00:01,  7.03it/s]\u001b[A\n",
            " 77%|███████▋  | 23/30 [00:03<00:01,  6.97it/s]\u001b[A\n",
            " 80%|████████  | 24/30 [00:03<00:00,  6.12it/s]\u001b[A\n",
            " 83%|████████▎ | 25/30 [00:03<00:00,  6.37it/s]\u001b[A\n",
            " 87%|████████▋ | 26/30 [00:03<00:00,  6.50it/s]\u001b[A\n",
            " 90%|█████████ | 27/30 [00:04<00:00,  6.51it/s]\u001b[A\n",
            " 93%|█████████▎| 28/30 [00:04<00:00,  6.63it/s]\u001b[A\n",
            " 97%|█████████▋| 29/30 [00:04<00:00,  6.72it/s]\u001b[A\n",
            "100%|██████████| 30/30 [00:04<00:00,  6.71it/s]\n",
            "\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "  3%|▎         | 1/30 [00:00<00:04,  6.44it/s]\u001b[A\n",
            "  7%|▋         | 2/30 [00:00<00:04,  6.63it/s]\u001b[A\n",
            " 10%|█         | 3/30 [00:00<00:04,  6.68it/s]\u001b[A\n",
            " 13%|█▎        | 4/30 [00:00<00:03,  6.81it/s]\u001b[A\n",
            " 17%|█▋        | 5/30 [00:00<00:03,  6.73it/s]\u001b[A\n",
            " 20%|██        | 6/30 [00:00<00:03,  6.77it/s]\u001b[A\n",
            " 23%|██▎       | 7/30 [00:01<00:03,  6.83it/s]\u001b[A\n",
            " 27%|██▋       | 8/30 [00:01<00:03,  6.93it/s]\u001b[A\n",
            " 30%|███       | 9/30 [00:01<00:03,  6.95it/s]\u001b[A\n",
            " 33%|███▎      | 10/30 [00:01<00:02,  6.83it/s]\u001b[A\n",
            " 37%|███▋      | 11/30 [00:01<00:02,  6.78it/s]\u001b[A\n",
            " 40%|████      | 12/30 [00:01<00:02,  6.87it/s]\u001b[A\n",
            " 43%|████▎     | 13/30 [00:01<00:02,  6.91it/s]\u001b[A\n",
            " 47%|████▋     | 14/30 [00:02<00:02,  6.87it/s]\u001b[A\n",
            " 50%|█████     | 15/30 [00:02<00:02,  6.87it/s]\u001b[A\n",
            " 53%|█████▎    | 16/30 [00:02<00:02,  6.95it/s]\u001b[A\n",
            " 57%|█████▋    | 17/30 [00:02<00:01,  6.98it/s]\u001b[A\n",
            " 60%|██████    | 18/30 [00:02<00:01,  6.97it/s]\u001b[A\n",
            " 63%|██████▎   | 19/30 [00:02<00:01,  7.03it/s]\u001b[A\n",
            " 67%|██████▋   | 20/30 [00:02<00:01,  7.02it/s]\u001b[A\n",
            " 70%|███████   | 21/30 [00:03<00:01,  7.03it/s]\u001b[A\n",
            " 73%|███████▎  | 22/30 [00:03<00:01,  6.86it/s]\u001b[A\n",
            " 77%|███████▋  | 23/30 [00:03<00:01,  6.93it/s]\u001b[A\n",
            " 80%|████████  | 24/30 [00:03<00:00,  6.95it/s]\u001b[A\n",
            " 83%|████████▎ | 25/30 [00:03<00:00,  6.07it/s]\u001b[A\n",
            " 87%|████████▋ | 26/30 [00:03<00:00,  6.30it/s]\u001b[A\n",
            " 90%|█████████ | 27/30 [00:03<00:00,  6.47it/s]\u001b[A\n",
            " 93%|█████████▎| 28/30 [00:04<00:00,  6.65it/s]\u001b[A\n",
            " 97%|█████████▋| 29/30 [00:04<00:00,  6.83it/s]\u001b[A\n",
            "100%|██████████| 30/30 [00:04<00:00,  6.81it/s]\n",
            "\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "  3%|▎         | 1/30 [00:00<00:04,  7.18it/s]\u001b[A\n",
            "  7%|▋         | 2/30 [00:00<00:03,  7.12it/s]\u001b[A\n",
            " 10%|█         | 3/30 [00:00<00:03,  7.11it/s]\u001b[A\n",
            " 13%|█▎        | 4/30 [00:00<00:03,  7.02it/s]\u001b[A\n",
            " 17%|█▋        | 5/30 [00:00<00:03,  7.04it/s]\u001b[A\n",
            " 20%|██        | 6/30 [00:00<00:03,  7.02it/s]\u001b[A\n",
            " 23%|██▎       | 7/30 [00:00<00:03,  7.06it/s]\u001b[A\n",
            " 27%|██▋       | 8/30 [00:01<00:03,  7.03it/s]\u001b[A\n",
            " 30%|███       | 9/30 [00:01<00:02,  7.02it/s]\u001b[A\n",
            " 33%|███▎      | 10/30 [00:01<00:02,  7.02it/s]\u001b[A\n",
            " 37%|███▋      | 11/30 [00:01<00:02,  7.06it/s]\u001b[A\n",
            " 40%|████      | 12/30 [00:01<00:02,  7.07it/s]\u001b[A\n",
            " 43%|████▎     | 13/30 [00:01<00:02,  6.95it/s]\u001b[A\n",
            " 47%|████▋     | 14/30 [00:01<00:02,  6.99it/s]\u001b[A\n",
            " 50%|█████     | 15/30 [00:02<00:02,  7.01it/s]\u001b[A\n",
            " 53%|█████▎    | 16/30 [00:02<00:02,  6.98it/s]\u001b[A\n",
            " 57%|█████▋    | 17/30 [00:02<00:01,  7.04it/s]\u001b[A\n",
            " 60%|██████    | 18/30 [00:02<00:01,  7.06it/s]\u001b[A\n",
            " 63%|██████▎   | 19/30 [00:02<00:01,  7.08it/s]\u001b[A\n",
            " 67%|██████▋   | 20/30 [00:02<00:01,  7.10it/s]\u001b[A\n",
            " 70%|███████   | 21/30 [00:02<00:01,  7.03it/s]\u001b[A\n",
            " 73%|███████▎  | 22/30 [00:03<00:01,  6.97it/s]\u001b[A\n",
            " 77%|███████▋  | 23/30 [00:03<00:00,  7.01it/s]\u001b[A\n",
            " 80%|████████  | 24/30 [00:03<00:00,  6.96it/s]\u001b[A\n",
            " 83%|████████▎ | 25/30 [00:03<00:00,  6.95it/s]\u001b[A\n",
            " 87%|████████▋ | 26/30 [00:03<00:00,  7.01it/s]\u001b[A\n",
            " 90%|█████████ | 27/30 [00:03<00:00,  6.94it/s]\u001b[A\n",
            " 93%|█████████▎| 28/30 [00:03<00:00,  6.96it/s]\u001b[A\n",
            " 97%|█████████▋| 29/30 [00:04<00:00,  6.01it/s]\u001b[A\n",
            "100%|██████████| 30/30 [00:04<00:00,  6.88it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zfpwc1XSGbYs",
        "outputId": "d0d16ae3-1bdf-4cf6-a43f-5fc68b94349b"
      },
      "source": [
        "# Check accuracy on training & test to see how good our model\n",
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    predicciones = []\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "            x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            predicciones.append(predictions)\n",
        "\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "    model.train()\n",
        "    return num_correct/num_samples, predicciones\n",
        "\n",
        "p_train, pred_train  = check_accuracy(train_loader, model)\n",
        "p_test, pred_test  = check_accuracy(test_loader, model)\n",
        "\n",
        "print(f\"Accuracy on training set: {p_train*100:.2f}\")\n",
        "print(f\"Accuracy on test set: {p_test*100:.2f}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 81.10\n",
            "Accuracy on test set: 82.42\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}