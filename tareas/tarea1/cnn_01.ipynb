{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn_01.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"CHWaizxAVVfq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"70eb66f5-a1aa-419a-dad3-2b7a32019e0a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3P7fWzuAZcO0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8a1298db-531c-4fc3-c3de-aef31ee34620"},"source":["import os\n","#OBTENER DATOS\n","\n","#Descomprimir\n","import tarfile\n","tar = tarfile.open(\"/content/drive/My Drive/Datasets/Cats&Dogs/fastai-datasets-cats-vs-dogs-2.tar\", 'r:')\n","#tar.extractall(\"/content/drive/My Drive/Datasets/Cats&Dogs\")\n","tar.extractall()\n","tar.close()\n","\n","#Borrar archivo .tar\n","#os.remove('/content/drive/My Drive/datasets/fastai-datasets-cats-vs-dogs-2.tar')\n","\n","#Comprobar las carpetas\n","os.listdir()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.config',\n"," 'train',\n"," 'sample',\n"," 'test1',\n"," 'valid',\n"," 'models',\n"," 'drive',\n"," 'sample_data']"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"zbu8jW4OgvhF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3d84e3fe-09b4-4a39-d465-2ebe86e9045c"},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\n","\n","model = Sequential()\n","model.add(Convolution2D(128, (3, 3), strides=(1,1), input_shape=(64,64,3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Convolution2D(64, (3,3), strides=(1,1), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Flatten())\n","model.add(Dense(256, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.summary()\n","\n","model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 62, 62, 128)       3584      \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 31, 31, 128)       0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 29, 29, 64)        73792     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 12544)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               3211520   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 3,289,153\n","Trainable params: 3,289,153\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tP8CzwihhCNA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4d7b6ed6-5b50-45d0-a3ff-a52b0f9b3d0f"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","#Definir Datagens\n","train_data_gen = ImageDataGenerator(\n","  rescale = 1./255, #Normalizacion para que los valores de las imagenes para que queden entre 0 y 1\n","  shear_range = 0.2, #Direccion de rotacion contrareloj\n","  zoom_range = 0.2, #Aplicacion de zoom aleatorio\n","  horizontal_flip = True # Va a invertir horizontalmente la imagen aleatoriamente\n",")\n","\n","test_data_gen = ImageDataGenerator(\n","  rescale = 1./255 #Normalizacion para que los valores de las imagenes para que queden entre 0 y 1\n",")\n","#Armar datasets\n","training_set = train_data_gen.flow_from_directory(\n","  \"train\",\n","  target_size = (64, 64), #Valores de nuestras capas de entrada (64, 64, 3)\n","  batch_size = 256,\n","  class_mode = \"binary\"\n",")\n","\n","test_set = test_data_gen.flow_from_directory(\"valid\",\n","                                           target_size = (64,64),\n","                                           batch_size = 256,\n","                                           class_mode = \"binary\"\n","                                           )\n","\n","\n","#Entrenar\n","model.fit_generator(\n","  training_set,\n","  epochs = 25,\n","  validation_data = test_set,\n",")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 23000 images belonging to 2 classes.\n","Found 2000 images belonging to 2 classes.\n","WARNING:tensorflow:From <ipython-input-5-69721a45fa01>:32: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.fit, which supports generators.\n","Epoch 1/25\n","90/90 [==============================] - 88s 980ms/step - loss: 0.6827 - accuracy: 0.5752 - val_loss: 0.6295 - val_accuracy: 0.6380\n","Epoch 2/25\n","90/90 [==============================] - 83s 924ms/step - loss: 0.6053 - accuracy: 0.6796 - val_loss: 0.6032 - val_accuracy: 0.6715\n","Epoch 3/25\n","90/90 [==============================] - 83s 921ms/step - loss: 0.5735 - accuracy: 0.7017 - val_loss: 0.5563 - val_accuracy: 0.7245\n","Epoch 4/25\n","90/90 [==============================] - 83s 925ms/step - loss: 0.5362 - accuracy: 0.7311 - val_loss: 0.5431 - val_accuracy: 0.7255\n","Epoch 5/25\n","90/90 [==============================] - 84s 929ms/step - loss: 0.5164 - accuracy: 0.7457 - val_loss: 0.5104 - val_accuracy: 0.7500\n","Epoch 6/25\n","90/90 [==============================] - 84s 931ms/step - loss: 0.5045 - accuracy: 0.7515 - val_loss: 0.4914 - val_accuracy: 0.7575\n","Epoch 7/25\n","90/90 [==============================] - 83s 927ms/step - loss: 0.4788 - accuracy: 0.7700 - val_loss: 0.4765 - val_accuracy: 0.7745\n","Epoch 8/25\n","90/90 [==============================] - 84s 928ms/step - loss: 0.4648 - accuracy: 0.7777 - val_loss: 0.4632 - val_accuracy: 0.7805\n","Epoch 9/25\n","75/90 [========================>.....] - ETA: 13s - loss: 0.4494 - accuracy: 0.7876"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4ocWVKyRkNoH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"33392475-8463-45bf-9e75-691e094e4b79"},"source":["#Predecir\n","from google.colab.files import upload #Colab\n","import numpy as np\n","#upload()\n","from keras.preprocessing import image\n","imagen = image.load_img(\"/content/gdrive/My Drive/Colab Notebooks/SIS421/CNN/p.jpg\", target_size=(64,64))\n","imagen = image.img_to_array(imagen)\n","imagen = np.expand_dims(imagen, axis=0) #(64, 64, 3) -> (1, 64, 64, 3) \n","res = model.predict_classes(imagen)\n","print('Resultado: ', res)\n","print('Etiquetas: ',training_set.class_indices)\n","\n","#os.mkdir('/content/gdrive/My Drive/Modelos')\n","model.save(\"/content/gdrive/My Drive/Modelos/DogVSCatModel.h5\")\n","\n","from tensorflow.keras.models import load_model\n","model = load_model('/content/gdrive/My Drive/Modelos/DogVSCatModel.h5')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Resultado:  [[1]]\n","Etiquetas:  {'cats': 0, 'dogs': 1}\n"],"name":"stdout"}]}]}